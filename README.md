# Image Denoising Project

This project implements various image denoising techniques, ranging from traditional filters to modern deep learning approaches. Built as part of my computer vision coursework.

## Project Structure

```
image_denoising/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ noisy/          # Noisy input images (all noise types)
â”‚   â””â”€â”€ clean/          # Clean ground truth images (all types)
â”‚
â”œâ”€â”€ traditional/        # Traditional denoising methods
â”‚   â”œâ”€â”€ gaussian.py     # Gaussian blur filter
â”‚   â”œâ”€â”€ median.py       # Median filter
â”‚   â”œâ”€â”€ bilateral.py    # Bilateral filter
â”‚   â”œâ”€â”€ nlm.py          # Non-Local Means
â”‚   â”œâ”€â”€ wiener.py       # Wiener filter
â”‚   â””â”€â”€ bm3d.py         # BM3D (placeholder)
â”‚
â”œâ”€â”€ deep/               # Deep learning methods (future)
â”‚   â”œâ”€â”€ dncnn.py        # DnCNN
â”‚   â”œâ”€â”€ unet_denoiser.py
â”‚   â”œâ”€â”€ autoencoder.py
â”‚   â”œâ”€â”€ diffusion.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ utils/              # Utility functions
â”‚   â”œâ”€â”€ metrics.py      # PSNR, SSIM, MSE
â”‚   â”œâ”€â”€ visualization.py # Plotting functions
â”‚   â”œâ”€â”€ image_io.py     # Image loading/saving
â”‚   â””â”€â”€ noise_estimation.py # Noise level estimation
â”‚
â”œâ”€â”€ configs/            # Configuration files
â”‚
â”œâ”€â”€ main.py             # Main CLI entry point
â”œâ”€â”€ evaluate.py         # Batch evaluation script
â””â”€â”€ README.md
```

## Dataset Organization

All images are organized in the `data/` directory with proper train/test/validation splits for deep learning:

```
data/
â”œâ”€â”€ train/ (80%)          # Training data
â”‚   â”œâ”€â”€ xray/            # Medical X-ray images (primary focus)
â”‚   â”œâ”€â”€ synthetic/       # Text and geometric shapes
â”‚   â””â”€â”€ natural/         # Natural scene images
â”œâ”€â”€ test/ (10%)          # Test data (same structure)
â””â”€â”€ validation/ (10%)    # Validation data (same structure)
```

Each category contains:
- `clean/` or `*_images/` - Ground truth clean images
- `gaussian_noise_*_sigma/` - Noisy versions at different sigma levels

### Types of Images

1. **X-Ray Medical Images** (Primary Focus)
   - 5000 medical X-ray images
   - Grayscale with varying contrast levels
   - Fine details and textures typical in diagnostic imaging
   - Noise levels: Ïƒ=15, Ïƒ=55
   - Critical for medical image processing applications

2. **Synthetic Images** (Text & Shapes)
   - **Lorem Ipsum Text Images**
     - Black/white text on colored backgrounds
     - Various fonts, sizes, and colors
     - Good for testing edge preservation and readability
   - **Geometric Shapes**
     - Simple shapes (circles, rectangles, triangles)
     - Clean edges and uniform colors
     - Ideal for quantitative edge preservation analysis
   - Noise levels: Ïƒ=15, Ïƒ=25, Ïƒ=50

3. **Natural Images** (Ready for Expansion)
   - Currently empty, ready for natural scene images
   - Will provide texture diversity for training
   - Complements medical and synthetic data

### Data Split Strategy

- **80% Training:** Used to train DnCNN model
- **10% Test:** Final evaluation, never seen during training
- **10% Validation:** Hyperparameter tuning and early stopping

Images are split consistently across all noise levels to maintain correspondence between clean/noisy pairs.

## Getting Started

Set up your environment:

```bash
# Create and activate a virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows users: .venv\Scripts\activate

# Install the required packages
pip install -r requirements.txt
```

## Usage

> **Note:** This project has three main scripts with different purposes:
> - **`main.py`** - For denoising and quick visualization  
> - **`generate_report.py`** - For comprehensive reports, error maps, PDFs, HTML
> - **`evaluate.py`** - For batch evaluation to CSV

### Basic Denoising (main.py)

```bash
# Denoise with a specific method
python main.py -n data/noisy -c data/clean -m bilateral --visualize

# Denoise with all methods and save results
python main.py -n data/noisy -c data/clean -m all -o output/

# Apply filter multiple times iteratively
python main.py -n data/noisy -c data/clean -m median --iterations 3 --visualize
```

### Auto-Tuning Parameters (main.py)

```bash
# Auto-tune parameters to find best PSNR
python main.py -n data/noisy -c data/clean -m bilateral --auto-tune

# Auto-tune for best SSIM with 20 iterations
python main.py -n data/noisy -c data/clean -m nlm --auto-tune --tune-metric ssim --tune-iterations 20

# Auto-tune with filter iterations optimization
python main.py -n data/noisy -c data/clean -m median --auto-tune --tune-iterations 30
```

### Method Comparison (main.py)

```bash
# Compare all methods with metrics and visualization
python main.py -n data/noisy -c data/clean --compare --visualize

# Compare specific number of images
python main.py -n data/noisy -c data/clean --compare --num-images 10

# Visualize multiple images with navigation (press q to continue)
python main.py -n data/noisy -c data/clean -m bilateral --visualize --num-images 5
```

### Comprehensive Reports (generate_report.py)

```bash
# Generate complete analysis report with all visualizations
python generate_report.py -n data/noisy -c data/clean --all

# Generate only error maps
python generate_report.py -n data/noisy -c data/clean --error-maps --num-images 5

# Generate only dataset-wide analysis plots
python generate_report.py -n data/noisy -c data/clean --dataset-plots

# Generate HTML report
python generate_report.py -n data/noisy -c data/clean --html-report

# Generate PDF report
python generate_report.py -n data/noisy -c data/clean --pdf-report
```

### Batch Evaluation (evaluate.py)

```bash
# Evaluate all methods and save results to CSV
python evaluate.py -n data/noisy -c data/clean -o results.csv

# Evaluate specific methods
python evaluate.py -n data/noisy -c data/clean --methods gaussian bilateral wiener
```

### Noise Estimation (main.py)

```bash
# Estimate noise levels in images
python main.py -n data/noisy -c data/clean --estimate-noise
```

## Available Methods

### Traditional Methods

1. **Gaussian Blur** (`gaussian`)
   - Fast, simple baseline
   - Blurs edges
   - Parameters: kernel_size, sigma

2. **Median Filter** (`median`)
   - Best for salt-and-pepper noise
   - Preserves edges
   - Parameters: kernel_size

3. **Bilateral Filter** (`bilateral`)
   - Edge-preserving smoothing
   - Good for Gaussian noise
   - Parameters: d, sigma_color, sigma_space

4. **Non-Local Means** (`nlm`)
   - State-of-the-art traditional method
   - Excellent for Gaussian noise
   - Parameters: h, template_window_size, search_window_size

5. **Wiener Filter** (`wiener`)
   - Optimal linear filter
   - Frequency domain filtering
   - Parameters: mysize, noise_variance

## Command Line Options

### Main Script (main.py)
```
  -n, --noisy PATH          Path to noisy images folder (required)
  -c, --clean PATH          Path to clean images folder (required)
  -m, --method METHOD       Denoising method: gaussian, median, bilateral, nlm, wiener, all
  -o, --output PATH         Output folder for denoised images
  --num-images N            Number of images to process (default: 5)
  --iterations N            Apply filter N times iteratively (default: 1)
  --compare                 Compare all methods with metrics
  --visualize               Show visualization plots
  --estimate-noise          Estimate noise levels
  --auto-tune               Use Bayesian optimization to find best parameters
  --tune-metric METRIC      Metric to optimize: psnr or ssim (default: psnr)
  --tune-iterations N       Number of optimization iterations (default: 15)
```

### Report Generation Script (generate_report.py)
```
  -n, --noisy PATH          Path to noisy images folder (required)
  -c, --clean PATH          Path to clean images folder (required)
  -o, --output PATH         Output folder for reports (default: ./reports)
  --num-images N            Number of images to process (default: 5)
  --error-maps              Generate error maps for each method
  --dataset-plots           Generate dataset-wide analysis plots
  --html-report             Generate HTML report with embedded visualizations
  --pdf-report              Generate PDF report with all plots
  --all                     Generate all reports (error maps, plots, HTML, PDF)
```

### Evaluation Script (evaluate.py)
```
  -n, --noisy PATH          Path to noisy images folder (required)
  -c, --clean PATH          Path to clean images folder (required)
  -o, --output PATH         Output CSV file for results
  --methods [METHODS]       Methods to evaluate
```

## How We Measure Quality

- **PSNR** (Peak Signal-to-Noise Ratio): Measures reconstruction quality. Higher values are better, usually between 20-40 dB for decent results.
- **SSIM** (Structural Similarity Index): Compares structural information. Ranges from -1 to 1, where 1 means the images are identical.

## Examples

### Example 1: Generate clean text images
```bash
python Make_Images.py -n 50 --width 800 --height 600 --output data/clean
```

### Example 2: Add noise to clean images
```bash
python Make_Noise.py -i data/clean -o data/noisy -t gaussian -s 25
```

### Example 3: Quick comparison with visualization
```bash
python main.py -n data/noisy -c data/clean --compare --visualize --num-images 3
```

### Example 4: Auto-tune bilateral filter for best SSIM
```bash
python main.py -n data/noisy -c data/clean -m bilateral --auto-tune --tune-metric ssim
```

### Example 5: Apply median filter 3 times iteratively
```bash
python main.py -n data/noisy -c data/clean -m median --iterations 3 --visualize
```

### Example 6: Denoise and save with Wiener filter
```bash
python main.py -n data/noisy -c data/clean -m wiener -o ./denoised_output
```

### Example 7: Batch evaluation to CSV
```bash
python evaluate.py -n data/noisy -c data/clean -o evaluation_results.csv
```

### Example 8: Generate comprehensive analysis report
```bash
python generate_report.py -n data/noisy/gaussian_noise_25_sigma -c data/clean/clean_images --all
```

### Example 9: Generate only error maps with noise distribution
```bash
python generate_report.py -n data/noisy -c data/clean --error-maps --num-images 5
```

### Example 10: Multi-image visualization (press q to navigate)
```bash
python main.py -n data/noisy -c data/clean -m nlm --visualize --num-images 10
```

## Wiener Filter Visualization

The Wiener filter provides additional frequency domain visualization showing:
- Fourier Transform (log magnitude) of the noisy image
- Wiener response in frequency domain

This helps understand how the filter attenuates different frequency components.

## Project Goals & Progress

### âœ… Completed

**1. Complete Image Denoising Benchmarking Framework**
- âœ… Unified loader for noisy and clean image pairs (`utils/image_io.py`)
- âœ… Unified interface for denoising methods
- âœ… Evaluation pipeline with PSNR, SSIM, MSE (`utils/metrics.py`)
- âœ… Visualization functions (`utils/visualization.py`)
- âœ… CLI to run experiments (`main.py`, `evaluate.py`)

**2. Traditional Image Denoising Methods**
- âœ… Gaussian blur with iterative support
- âœ… Median filtering with iterative support
- âœ… Bilateral filtering with iterative support
- âœ… Non-local means (NLM)
- âœ… Wiener filtering with FFT visualization
- âœ… Bayesian parameter auto-tuning (`--auto-tune`)
- âœ… Noise estimation (MAD method)
- âœ… Batch processing support

**3. Evaluation Metrics**
- âœ… PSNR, SSIM, MSE
- âœ… Runtime measurements
- âœ… Robustness testing across noise levels

**4. Visualization & Reporting**
- âœ… Side-by-side comparisons
- âœ… FFT visualizations (Wiener filter)
- âœ… Multi-image visualization with navigation
- âœ… Error maps (`utils/error_maps.py`)
- âœ… Dataset-wide plots (`utils/dataset_plots.py`)
- âœ… PDF/HTML report generation (`utils/report_generation.py`)

**5. CLI Features**
- âœ… Run specific methods (`-m/--method`)
- âœ… Benchmark all methods (`--compare`)
- âœ… Auto-tune parameters (`--auto-tune`)
- âœ… Iterative filtering (`--iterations`)
- âœ… Save outputs (`-o/--output`)
- âœ… Noise estimation (`--estimate-noise`)
- âœ… Visualization (`--visualize`)

**6. Modular Architecture**
- âœ… Separate directories for traditional, utils, deep, configs
- âœ… Clean separation of concerns
- âœ… Plug-in structure for adding new methods

### â³ In Progress

**7. Deep Learning Denoising Models - DnCNN Training**

**Current Status:** Preparing dataset and infrastructure for DnCNN training

**What We're Doing Now:**
- âœ… Dataset preparation with proper splits (80% train / 10% test / 10% validation)
- âœ… Adding Gaussian noise at multiple sigma levels (Ïƒ=15, 25, 55) to XRAY images
- âœ… Organizing data into structured folders: `data/train/`, `data/test/`, `data/validation/`
- âœ… Maintaining XRAY-focused distribution (medical imaging priority)
- âœ… Including synthetic images (shapes, text) and natural images for diversity
- ğŸ”„ Creating data reorganization utilities (`deep/utils/move_data.py`)

**Dataset Composition:**
- **XRAY Images** (Largest category, primary focus)
  - 5000 medical X-ray images
  - Noise levels: Ïƒ=15, Ïƒ=55
  - Location: `data/train/xray/`
  
- **Synthetic Images** (Text & shapes)
  - Lorem ipsum text images with varying fonts/colors
  - Geometric shapes with clean edges
  - Noise levels: Ïƒ=15, Ïƒ=25, Ïƒ=50
  - Location: `data/train/synthetic/`
  
- **Natural Images** (Empty for now, ready for expansion)
  - Location: `data/train/natural/`

**Next Steps (In Order):**
1. ğŸ”„ Finalize data reorganization script and execute split
2. ğŸ“‹ Install PyTorch and dependencies (`torch`, `torchvision`)
3. ğŸ“‹ Implement DnCNN architecture (17-layer CNN with residual learning)
   - Create `deep/dncnn.py` with model definition
   - Implement residual noise learning (predict noise, not clean image)
4. ğŸ“‹ Create PyTorch Dataset class (`deep/dataset.py`)
   - Wrap existing image loaders from `utils/image_io.py`
   - Extract 40Ã—40 patches for training
   - Implement data augmentation (flips, rotations)
5. ğŸ“‹ Build training infrastructure (`train.py` or `deep/train_dncnn.py`)
   - Training loop with GPU support
   - Validation loop using existing metrics (PSNR/SSIM)
   - Checkpoint management and model saving
   - TensorBoard logging for loss curves
   - Learning rate scheduling
6. ğŸ“‹ Create configuration system (`configs/dncnn_train.yaml`)
   - Model hyperparameters (depth, channels, batch size)
   - Training parameters (learning rate, epochs, optimizer)
   - Data paths and augmentation settings
7. ğŸ“‹ Implement inference wrapper
   - Create `dncnn_denoise()` function matching traditional method signatures
   - Integrate with existing `main.py` CLI (add `-m dncnn` option)
8. ğŸ“‹ Training and evaluation
   - Train on Ïƒ=25 Gaussian noise (primary noise level)
   - Validate generalization on Ïƒ=15 and Ïƒ=55
   - Compare DnCNN vs traditional methods (bilateral, NLM, BM3D)
   - Generate comprehensive reports with `generate_report.py`

**Technical Details:**
- **Model:** DnCNN-S (17 convolutional layers)
  - Architecture: Conv + ReLU â†’ (Conv + BatchNorm + ReLU) Ã— 15 â†’ Conv
  - Residual learning: Network predicts noise, not clean image
  - Formula: `Clean = Noisy - Predicted_Noise`
- **Training:** 
  - Loss: MSE between predicted and actual noise
  - Optimizer: Adam with learning rate decay
  - Batch size: 128 patches (40Ã—40)
  - Data augmentation: Random flips, rotations
- **Evaluation:** PSNR, SSIM on held-out test set

**8. Configurable Experiment System**
- ğŸ“‹ YAML/JSON configs for reproducibility (directory created, implementing next)

### ğŸ“‹ Planned

**9. Advanced DnCNN Features**
- ğŸ“‹ Multi-noise-level training (blind denoising model)
- ğŸ“‹ Color image support (currently grayscale-focused)
- ğŸ“‹ Real-time inference optimization
- ğŸ“‹ Model ensemble for improved performance
- ğŸ“‹ Transfer learning from pre-trained models

**10. Additional Deep Learning Models**
- ğŸ“‹ UNet-based denoiser (encoder-decoder architecture)
- ğŸ“‹ Denoising autoencoder (latent space learning)
- ğŸ“‹ Diffusion models (state-of-the-art generative approach)
- ğŸ“‹ Self-supervised denoisers (Noise2Noise, Noise2Void)

**11. Advanced Features & Datasets**
- ğŸ“‹ Real-noise datasets (SIDD, DND) for practical evaluation
- ğŸ“‹ Additional noise types (Poisson, speckle, motion blur)
- ğŸ“‹ LPIPS perceptual metric for quality assessment
- ğŸ“‹ Mixed precision training (faster on modern GPUs)

**12. Reporting & Comparison**
- ğŸ“‹ Traditional vs deep learning performance study
- ğŸ“‹ Computational efficiency analysis (speed vs quality)
- ğŸ“‹ Strengths and weaknesses analysis per method
- ğŸ“‹ Domain-specific performance (medical vs natural vs synthetic)

**13. Stretch Goals**
- ğŸ“‹ Optional GUI interface for interactive denoising
- ğŸ“‹ Web app demo with model deployment
- ğŸ“‹ Publish as open-source package
- ğŸ“‹ Real-time video denoising demo
- ğŸ“‹ Integration with medical imaging pipelines

## References

- Traditional denoising: OpenCV documentation
- Wiener filter: scipy.signal.wiener
- Metrics: scikit-image
- Bayesian optimization: scikit-optimize

